{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlv6knX04FiY"
   },
   "source": [
    "# Mount Notebook to Google Drive\n",
    "Dataset: https://ars.els-cdn.com/content/image/1-s2.0-S2352340917303487-mmc2.csv\n",
    "\n",
    "Data Name: '1-s2.0-S2352340917303487-mmc2.csv'\n",
    "\n",
    "Naming Convention: '/content/drive/MyDrive/CSE6250/1-s2.0-S2352340917303487-mmc2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfk8Zrul_E8V"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQ0sNuMePBXx"
   },
   "source": [
    "# Introduction\n",
    "## Background of the problem:\n",
    "\n",
    "**Problem type:** Multi-label classification of Psychotic Disorder Diseases (PDD) using patient medical records.  \n",
    "**Importance:** Accurate classification of PDD is crucial for early diagnosis, tailored treatment plans, and improved patient outcomes. It can assist clinicians in making informed decisions.  \n",
    "**Difficulty:** PDD classification is challenging due to overlapping symptoms, heterogeneous patient populations, and the presence of multiple comorbid conditions. Moreover, medical records often contain class imbalances and missing data.  \n",
    "**State of the art:** Traditional methods rely on clinical expertise and diagnostic criteria like DSM-5. Machine learning approaches such as support vector machines and decision trees have been applied, but their performance is limited by the complexity of PDD.\n",
    "\n",
    "## Paper explanation:\n",
    "\n",
    "**Proposal:** The paper \"Application of deep and machine learning techniques for multi-label classification performance on psychotic disorder diseases\" by Israel Elujide et al. proposes using deep learning (multilayer perceptron) and machine learning techniques (random forest, SVM, decision tree) for multi-label PDD classification. They also employ SMOTE oversampling to handle class imbalance.  \n",
    "**Innovations:**\n",
    "- Application of deep learning to PDD classification, which can capture complex non-linear relationships in the data.\n",
    "- Use of SMOTE oversampling to address class imbalance, which is a common issue in medical datasets.\n",
    "- Analysis of feature importances and correlations to gain insights into PDD risk factors.\n",
    "\n",
    "**Effectiveness:** The proposed deep learning model achieved an accuracy of 75.17% on an imbalanced test set, outperforming machine learning techniques. The random forest model obtained 64.1% accuracy on a balanced dataset after SMOTE oversampling.  \n",
    "**Contributions:**\n",
    "- Demonstrates the potential of deep learning for improving PDD classification, which could aid in clinical decision support.\n",
    "- Highlights the importance of addressing class imbalance in medical data using techniques like SMOTE.\n",
    "- Identifies key features (e.g., age) and correlations (e.g., bipolar disorder and insomnia) that contribute to PDD risk, which could inform future research and interventions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uygL9tTPSVHB"
   },
   "source": [
    "# Scope of Reproducibility\n",
    "\n",
    "## Hypotheses to Test:\n",
    "\n",
    "1. **Hypothesis:** Deep learning with multilayer perceptron (MLP) will perform better than machine learning techniques like SVM, RF, and DT for multi-label psychotic disorder classification on an imbalanced dataset.\n",
    "   - **Experiment:** Train and evaluate MLP, SVM, RF, and DT models on the imbalanced PDD dataset. Compare their classification accuracies.\n",
    "\n",
    "2. **Hypothesis:** Machine learning with RF will outperform deep learning on a balanced dataset after using SMOTE oversampling to handle class imbalance.\n",
    "   - **Experiment:** Apply SMOTE oversampling to the training data to balance the class distribution. Train and evaluate MLP and RF models on the balanced dataset. Compare their classification accuracies.\n",
    "\n",
    "3. **Hypothesis:** Patient age will be the most important feature contributing to model performance.\n",
    "   - **Experiment:** Train a random forest model on the PDD dataset and extract feature importances. Examine if age is ranked as the most important feature.\n",
    "\n",
    "4. **Hypothesis:** There will be a strong correlation between bipolar disorder and insomnia diagnoses.\n",
    "   - **Experiment:** Calculate the pairwise correlation between bipolar disorder and insomnia labels in the dataset. Check if the correlation coefficient indicates a strong positive relationship.\n",
    "\n",
    "## Expected Results to Validate:\n",
    "\n",
    "- The deep learning model will achieve an accuracy of ~75% on the imbalanced test set.\n",
    "- The RF model will achieve ~64% on the balanced set.\n",
    "\n",
    "## Experimental Setup:\n",
    "\n",
    "- Train the MLP model on the imbalanced dataset.\n",
    "- Train the RF model on the balanced dataset (after SMOTE oversampling).\n",
    "\n",
    "## Evaluation Metrics:\n",
    "\n",
    "- Evaluate the accuracies of the MLP and RF models on their respective test sets.\n",
    "- Compare the achieved accuracies with the reported values in the paper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWAHJ_1CdtaA"
   },
   "source": [
    "# Methodology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yu61Jp1xrnKk"
   },
   "outputs": [],
   "source": [
    "# import  packages you need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NbPHUTMbkD3"
   },
   "source": [
    "# Data Description and Processing\n",
    "\n",
    "## Data Source:\n",
    "\n",
    "- **Source:** The dataset used in this study is obtained from the paper \"Application of deep and machine learning techniques for multi-label classification performance on psychotic disorder diseases\" by Israel Elujide et al.\n",
    "- **Dataset:** Provided as a supplementary file with the paper (1-s2.0-S2352914821000356-mmc2.csv).\n",
    "- **Origin:** Yaba Psychiatry Hospital, Yaba, Lagos State, Nigeria.\n",
    "- **Time Span:** Five years (Jan. 2010â€“Dec. 2014).\n",
    "- **Size:** 500 patient records.\n",
    "- **Features:** 16 variables (11 independent and 5 dependent variables).\n",
    "- **Class Labels:** 5 psychotic disorder diseases (PDD) - bipolar disorder, vascular dementia, attention-deficit/hyperactivity disorder (ADHD), insomnia, and schizophrenia.\n",
    "- **Label Distribution:**\n",
    "  - Bipolar disorder: 40.2% positive\n",
    "  - Insomnia: 40.6% positive\n",
    "  - Schizophrenia: 75% positive\n",
    "  - ADHD: 43.6% positive\n",
    "  - Vascular dementia: 69.2% positive\n",
    "- **Cross-validation:** 70% training set, 30% testing set.\n",
    "\n",
    "## Data Processing Steps:\n",
    "\n",
    "1. **Handle Missing Values:**\n",
    "   - Remove records with missing data.\n",
    "2. **Encode Categorical Variables:**\n",
    "   - Use one-hot encoding for categorical variables.\n",
    "3. **Handle Class Imbalance:**\n",
    "   - Apply SMOTE oversampling on the training set to balance class distribution.\n",
    "4. **Data Splitting:**\n",
    "   - Split the dataset into 70% training and 30% testing sets using stratified sampling to preserve class ratios.\n",
    "\n",
    "## Illustration:\n",
    "\n",
    "- **Print Dataset Information:**\n",
    "  - Display the shape, head, and summary statistics of the dataset.\n",
    "- **Visualize Class Distribution:**\n",
    "  - Plot bar charts showing the class distribution before and after SMOTE oversampling.\n",
    "- **Visualize Correlation Matrix:**\n",
    "  - Display the correlation matrix between features and labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzVUQS0CHry0"
   },
   "source": [
    "For TA to grade your submission, please share access to TAs' google accounts through adding the 4 gmails as Editor. Thanks!\n",
    "\n",
    "*   Quan Guo: gqsavannah@gmail.com\n",
    "*   Yuzheng Liu: liuyz0218@gmail.com\n",
    "*   Bojun Li: bojunli412@gmail.com\n",
    "*   Jinhan Zhao: walt980626@gmail.com\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZScZNbROw-N"
   },
   "outputs": [],
   "source": [
    "# Load the dataset from Google Drive\n",
    "data = pd.read_csv('/content/drive/MyDrive/CSE6250/1-s2.0-S2352340917303487-mmc2.csv', encoding='latin1')\n",
    "\n",
    "# Handle missing values first\n",
    "data = data.dropna()\n",
    "\n",
    "# Separate features and labels\n",
    "features = ['Insominia', 'shizopherania', 'vascula_demetia', 'MBD', 'Bipolar']\n",
    "X = data.drop(features, axis=1)\n",
    "y = data[features].apply(lambda x: x.str[0]).replace({'N': 0, 'P': 1})\n",
    "\n",
    "binaryColumns = ['sex', 'faNoily_status', 'loss_of_parent', 'divorse', 'Injury', 'Spiritual_consult']\n",
    "\n",
    "for col in binaryColumns:\n",
    "  X[col] = X[col].map({'Yes': 1, 'No': 0, 'F': 1, 'M': 0})\n",
    "\n",
    "# One-hot encode categorical variables and normalize\n",
    "cat_cols = ['religion', 'genetic', 'occupation', 'status', 'agecode']\n",
    "onehot = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "scaler = StandardScaler()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', onehot, cat_cols),\n",
    "        ('scaler', scaler, X.select_dtypes(include=['int64', 'float64']).columns)\n",
    "    ])\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6250 * 5)\n",
    "\n",
    "# Apply SMOTE oversampling for each target label separately\n",
    "X_train_sm, y_train_sm = X_train.copy(), y_train.copy()\n",
    "for column in y_train.columns:\n",
    "    # Count the number of occurrences of each class\n",
    "    class_counts = y_train[column].value_counts()\n",
    "\n",
    "    # Determine the majority and minority classes\n",
    "    majority_class = class_counts.idxmax()\n",
    "    minority_class = class_counts.idxmin()\n",
    "\n",
    "    # Calculate the number of samples to generate for the minority class\n",
    "    num_samples = class_counts[majority_class] - class_counts[minority_class]\n",
    "\n",
    "    # Apply SMOTE only if there is a class imbalance and the minority class has at least 2 samples\n",
    "    if num_samples > 0 and class_counts[minority_class] >= 2:\n",
    "        smote = SMOTE(random_state=42, k_neighbors=max(1, min(5, class_counts[minority_class] - 1)))\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train[column])\n",
    "        y_train_sm[column] = y_resampled\n",
    "    else:\n",
    "        print(f\"Skipping SMOTE for column '{column}' due to insufficient minority class samples.\")\n",
    "\n",
    "# Scale the features after SMOTE\n",
    "X_train_sm = scaler.fit_transform(X_train_sm)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(\"Dataset size:\", data.shape)\n",
    "print(\"Training set size:\", X_train_sm.shape, y_train_sm.shape)\n",
    "print(\"Test set size:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Visualize class distribution before and after SMOTE\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.countplot(x=data['Insominia'], ax=axs[0]).set_title(\"Before SMOTE\")\n",
    "sns.countplot(x=y_train_sm['Insominia'], ax=axs[1]).set_title(\"After SMOTE\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize feature correlations\n",
    "corr = data.corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3muyDPFPbozY"
   },
   "source": [
    "# Model Architecture and Code Structure\n",
    "\n",
    "## Model Architectures:\n",
    "\n",
    "### Deep Learning (MLP):\n",
    "- **Input Layer:** 15 nodes (one-hot encoded features).\n",
    "- **Hidden Layers:** 3 layers with 20, 20, and 40 nodes respectively.\n",
    "- **Output Layer:** 5 nodes (one for each PDD label).\n",
    "- **Activation Functions:** ReLU for hidden layers, sigmoid for output layer.\n",
    "- **Regularization:** Dropout layers\n",
    "\n",
    "### Machine Learning:\n",
    "- **Support Vector Machine (SVM) with RBF kernel.**\n",
    "- **Random Forest (RF) with 100 trees.**\n",
    "- **Decision Tree (DT) with Gini impurity criterion.**\n",
    "\n",
    "## Training Objectives:\n",
    "\n",
    "- **Loss Function:** Binary cross-entropy for MLP, as it is a multi-label classification task.\n",
    "- **Optimizer:** Adam with learning rate 0.01.\n",
    "- **Epochs:** 40 with early stopping based on validation loss.\n",
    "- **Batch Size:** 50.\n",
    "\n",
    "## Other Details:\n",
    "\n",
    "- The models are trained from scratch without any pretraining.\n",
    "- 5-fold cross-validation is used for hyperparameter tuning.\n",
    "\n",
    "## Code Structure:\n",
    "\n",
    "- Define a `MLP` class in Keras with the specified architecture.\n",
    "- Implement functions for training, validation, and testing the MLP model.\n",
    "- Use scikit-learn library for SVM, RF, and DT models.\n",
    "- Develop functions to train and evaluate these models with the same data splits as MLP.\n",
    "- Save the best performing models for each architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiiwawoYCgnI"
   },
   "outputs": [],
   "source": [
    "# Convert the data to float32\n",
    "X_train_sm = np.array(X_train_sm).astype('float32')\n",
    "\n",
    "# Convert to numpy array and float32 after encoding\n",
    "y_train_sm = np.array(y_train_sm).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1p2dHXBoCmdt"
   },
   "outputs": [],
   "source": [
    "# Check for NaN values and handle them if any\n",
    "X_train_sm = np.nan_to_num(X_train_sm)\n",
    "y_train_sm = np.nan_to_num(y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBdVZoTvsSFV"
   },
   "outputs": [],
   "source": [
    "def create_mlp(input_shape):\n",
    "    model = Sequential([\n",
    "        Dropout(0.1, input_shape=(24,)),\n",
    "        Dense(20, activation='relu', input_shape=(input_shape,)),\n",
    "        Dropout(0.1, input_shape=(20,)),\n",
    "        Dense(20, activation='relu'),\n",
    "        Dropout(0.5, input_shape=(20,)),\n",
    "        Dense(40, activation='relu'),\n",
    "        Dropout(0.5, input_shape=(40,)),\n",
    "        Dense(5, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer= keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train the MLP model with early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "mlp_model = create_mlp(X_train.shape[1])\n",
    "history = mlp_model.fit(X_train, y_train, epochs=40, batch_size=50, validation_data = (X_test, y_test), callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('mlp_loss_plot.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('mlp_loss_plot.png')\n",
    "plt.show()\n",
    "\n",
    "# Hyperparameter tuning for RF\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=5)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_model = rf_grid.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters for Random Forest\n",
    "print(\"Best hyperparameters for Random Forest:\")\n",
    "print(rf_grid.best_params_)\n",
    "\n",
    "# Assuming you want to use SVM for multi-label classification\n",
    "svm_model = OneVsRestClassifier(SVC(random_state=42))\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Similar for Decision Tree\n",
    "dt_model = OneVsRestClassifier(DecisionTreeClassifier(random_state=42))\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# After training the models\n",
    "mlp_preds = mlp_model.predict(X_test)\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "svm_preds = svm_model.predict(X_test)\n",
    "dt_preds = dt_model.predict(X_test)\n",
    "\n",
    "# Apply threshold to convert continuous predictions to binary\n",
    "threshold = 0.5\n",
    "mlp_preds_binary = (mlp_preds > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX6bCcZNuxmz"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjW9bCkouv8O"
   },
   "outputs": [],
   "source": [
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"mlp_preds_binary shape:\", mlp_preds_binary.shape)\n",
    "print(\"\\nFirst few rows of y_test:\")\n",
    "print(y_test.head())\n",
    "print(mlp_preds_binary[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUtPDyNMKxaJ"
   },
   "outputs": [],
   "source": [
    "y_test_binary = y_test\n",
    "\n",
    "# Now, evaluate the models with y_test_binary\n",
    "print(\"\\nMLP Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_binary, mlp_preds_binary))\n",
    "print(\"Precision:\", precision_score(y_test_binary, mlp_preds_binary, average='micro'))\n",
    "print(\"Recall:\", recall_score(y_test_binary, mlp_preds_binary, average='micro'))\n",
    "print(\"F1-score:\", f1_score(y_test_binary, mlp_preds_binary, average='micro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPu_NKFnKvGF"
   },
   "outputs": [],
   "source": [
    "# Evaluate the models using multi-label classification metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"MLP Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_binary, mlp_preds_binary))\n",
    "print(\"Precision:\", precision_score(y_test_binary, mlp_preds_binary, average='micro'))\n",
    "print(\"Recall:\", recall_score(y_test_binary, mlp_preds_binary, average='micro'))\n",
    "print(\"F1-score:\", f1_score(y_test_binary, mlp_preds_binary, average='micro'))\n",
    "\n",
    "print(\"\\nRF Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_binary, rf_preds))\n",
    "print(\"Precision:\", precision_score(y_test_binary, rf_preds, average='micro'))\n",
    "print(\"Recall:\", recall_score(y_test_binary, rf_preds, average='micro'))\n",
    "print(\"F1-score:\", f1_score(y_test_binary, rf_preds, average='micro'))\n",
    "\n",
    "print(\"\\nSVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_binary, svm_preds))\n",
    "print(\"Precision:\", precision_score(y_test_binary, svm_preds, average='micro'))\n",
    "print(\"Recall:\", recall_score(y_test_binary, svm_preds, average='micro'))\n",
    "print(\"F1-score:\", f1_score(y_test_binary, svm_preds, average='micro'))\n",
    "\n",
    "print(\"\\nDT Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_binary, dt_preds))\n",
    "print(\"Precision:\", precision_score(y_test_binary, dt_preds, average='micro'))\n",
    "print(\"Recall:\", recall_score(y_test_binary, dt_preds, average='micro'))\n",
    "print(\"F1-score:\", f1_score(y_test_binary, dt_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EAWAy_LwHlV"
   },
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH75TNU71eRH"
   },
   "source": [
    "# Model Evaluation Metrics and Analysis\n",
    "\n",
    "## MLP Metrics:\n",
    "\n",
    "- **Accuracy:** 0.3133\n",
    "- **Precision:** 0.7617\n",
    "- **Recall:** 0.7990\n",
    "- **F1-score:** 0.7799\n",
    "\n",
    "The MLP model has an accuracy of 0.31, indicating that it correctly predicts 31% of the instances completely. However, the precision of 0.76 means that 76% of instances predicted as positive are actually positive. The recall of 0.80 suggests that the model identifies 80% of actual positives are identified correctly. The F1-score of 0.78 provides a balanced measure of the model's performance and suggest that we have a good balance between both.This indicates we might need to rethink our accuracy and precision calculations\n",
    "\n",
    "## RF Metrics:\n",
    "\n",
    "- **Accuracy:** 0.36\n",
    "- **Precision:** 0.7937\n",
    "- **Recall:** 0.8015\n",
    "- **F1-score:** 0.7976\n",
    "\n",
    "The Random Forest (RF) model has a slightly higher accuracy of 0.36 compared to the MLP model. It has a precision of 0.79, indicating that 79% of instances predicted as positive are actually positive. The recall of 0.80 suggests that the model identifies 80% of actual positives are identified correctly. The F1-score of 0.8 provides a balanced measure of the model's performance and suggests the random forest is also balanced, but suffers from the same accuracy issue as the mlp.\n",
    "\n",
    "## SVM Metrics:\n",
    "\n",
    "- **Accuracy:** 0.32\n",
    "- **Precision:** 0.7446\n",
    "- **Recall:** 0.7574\n",
    "- **F1-score:** 0.7509\n",
    "\n",
    "The Support Vector Machine (SVM) model has an accuracy of 0.32, slightly higher than the MLP model but lower than the RF model. It has a precision of 0.74, indicating that 74% of instances predicted as positive are actually positive. The recall of 0.76 suggests that the model identifies 76% of actual positive instances. The F1-score of 0.75 provides a balanced measure of the model's performance and suggests that the SVM is well balanced, but less so then the previous models.\n",
    "\n",
    "## DT Metrics:\n",
    "\n",
    "- **Accuracy:** 0.2533\n",
    "- **Precision:** 0.7330\n",
    "- **Recall:** 0.7132\n",
    "- **F1-score:** 0.7230\n",
    "\n",
    "The Decision Tree (DT) model has the lowest accuracy among all models, with a value of 0.25. It has a precision of 0.73, indicating that 73% of instances predicted as positive are actually positive. The recall of 0.71 suggests that the model identifies 71% of actual positive instances. The F1-score of 0.72 provides a balanced measure of the model's performance and shows that the DT is the worst.\n",
    "\n",
    "## Overall Analysis:\n",
    "\n",
    "Based on the evaluation metrics, the Random Forest (RF) model performs the best among all models, with the highest accuracy, precision, and F1-score. The MLP and SVM models have comparable performance, while the Decision Tree (DT) model has the lowest performance.\n",
    "\n",
    "However, all models exhibit relatively low accuracies, indicating the challenging nature of the multi-label classification task for psychotic disorder diseases. There may be opportunities for improvement through model architecture adjustments, hyperparameter tuning, and feature engineering. Techniques such as addressing class imbalance and exploring additional features could also enhance model performance. In addition, tuning the way we measure accuracy in the project could shed light on the low accuracy scores.\n",
    "\n",
    "Further analysis and experimentation are recommended to improve the models' accuracy and effectiveness in predicting psychotic disorder diseases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQL2ZQbWMkmH"
   },
   "source": [
    "# Discussion\n",
    "\n",
    "The results obtained from the multi-label classification of psychotic disorder diseases using deep learning and machine learning models provide valuable insights into the performance and challenges associated with this task.\n",
    "\n",
    "## Model Performance Analysis:\n",
    "\n",
    "- **MLP (Multilayer Perceptron) Model:**\n",
    "\n",
    "  The MLP model demonstrates relatively high precision and recall, but low accuracy which means we maybe missing a classification in most rows.\n",
    "\n",
    "- **Random Forest (RF) Model:**\n",
    "\n",
    "  The RF model outperforms the MLP model in terms of precision and recall, but the margin is very slight.\n",
    "\n",
    "- **Support Vector Machine (SVM) Model:**\n",
    "\n",
    "  The SVM model shows comparable performance to the MLP model with slightly higher accuracy but lower precision and recall.\n",
    "\n",
    "- **Decision Tree (DT) Model:**\n",
    "\n",
    "  The DT model exhibits the lowest performance among all models.\n",
    "\n",
    "## Strategies for Improvement:\n",
    "\n",
    "1. **Feature Engineering:**\n",
    "   Explore additional relevant features for better discrimination.\n",
    "   \n",
    "2. **Hyperparameter Tuning:**\n",
    "   Conduct extensive hyperparameter tuning for optimal model performance.\n",
    "   \n",
    "3. **Model Ensemble:**\n",
    "   Combine predictions from multiple models using ensemble techniques.\n",
    "   \n",
    "4. **Class Imbalance Handling:**\n",
    "   Address class imbalance using techniques like class weighting or oversampling.\n",
    "   \n",
    "5. **Advanced Architectures:**\n",
    "   Investigate advanced deep learning architectures like CNNs or RNNs.\n",
    "   \n",
    "6. **Data Augmentation:**\n",
    "   Apply data augmentation techniques to increase diversity in the training data.\n",
    "   \n",
    "7. **Interpretability Analysis:**\n",
    "   Understand model features and patterns for further insights.\n",
    "\n",
    "8. **Change Classification Target:**\n",
    "To better understand the relationship between target variables\n",
    "\n",
    "9. **Use Balanced Dataset:**Having a SMOTE dataset to train in tandem to the imbalanced dataset we have will help test the overall paper's conclusion\n",
    "\n",
    "## Conclusion:\n",
    "\n",
    "The challenges associated with multi-label classification of psychotic disorder diseases are evident from the models' performance. However, with optimization strategies and iterative refinement, it's possible to improve model accuracy and reliability for this complex task. To further the experiment we also need to test out different setups for classification such as: aggregating all 5 classification targets into a single classification target and using the other four targets to predict a single classification to test the robustness of our models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHMI2chl9omn"
   },
   "source": [
    "# References\n",
    "\n",
    "1.  Elujide, Israel et al, Application of deep and machine learning techniques for multi-label classification performance on psychotic disorder diseases, Informatics in Medicine Unlocked, Volume 23, 2021, https://www.sciencedirect.com/science/article/pii/S2352914821000356\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
